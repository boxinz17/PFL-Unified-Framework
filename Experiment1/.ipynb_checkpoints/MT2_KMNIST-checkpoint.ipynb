{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23849c10f50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages and set up default settings\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import data_load\n",
    "import MT2\n",
    "\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all parameters\n",
    "lambda_global = 10\n",
    "lambda_penal = 1\n",
    "\n",
    "M = 10\n",
    "n_samples = 100\n",
    "\n",
    "obj = 'MT2'\n",
    "data_name = 'KMNIST'\n",
    "\n",
    "L_w = (lambda_global + lambda_penal) / M\n",
    "L_beta = 1 + lambda_penal\n",
    "\n",
    "prob1 = L_w / (L_w + L_beta)\n",
    "prob2 = 1 - prob1\n",
    "\n",
    "eta = 1e-1\n",
    "\n",
    "rho = 1e-2\n",
    "\n",
    "n_communs = 1000\n",
    "repo_step = 100\n",
    "sync_step = 5\n",
    "\n",
    "w0 = [torch.zeros(10, 784).to(device), torch.zeros(10).to(device)]\n",
    "\n",
    "beta0 = []\n",
    "for m in range(M):\n",
    "    beta0.append([torch.zeros(10, 784).to(device), torch.zeros(10).to(device)])\n",
    "    \n",
    "w_list0 = []\n",
    "for m in range(M):\n",
    "    w_list0.append([torch.zeros(10, 784).to(device), torch.zeros(10).to(device)])\n",
    "\n",
    "beta_list0 = []\n",
    "for m in range(M):\n",
    "    beta_list0.append([torch.zeros(10, 784).to(device), torch.zeros(10).to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_w is: 1.1\n",
      "L_beta is 0.2\n",
      "prob1 is 0.8461538461538461\n",
      "prob2 is 0.15384615384615385\n",
      "eta is 0.1\n",
      "rho is 0.01\n",
      "n_communs is 1000\n",
      "sync_step is 5\n"
     ]
    }
   ],
   "source": [
    "print(\"L_w is: {}\".format(L_w))\n",
    "print(\"L_beta is {}\".format(L_beta))\n",
    "print(\"prob1 is {}\".format(prob1))\n",
    "print(\"prob2 is {}\".format(prob2))\n",
    "print(\"eta is {}\".format(eta))\n",
    "print(\"rho is {}\".format(rho))\n",
    "print(\"n_communs is {}\".format(n_communs))\n",
    "print(\"sync_step is {}\".format(sync_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_list, devices_train_list = data_load.data_prepare(data_name, n_devices=M, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_commun: 1, loss: 25.3284320831, time pass: 0s | Local_SGD MT2 KMNIST\n",
      "num_commun: 100, loss: 24.7518733978, time pass: 19s | Local_SGD MT2 KMNIST\n",
      "num_commun: 200, loss: 24.4187985420, time pass: 39s | Local_SGD MT2 KMNIST\n",
      "num_commun: 300, loss: 24.1247526169, time pass: 58s | Local_SGD MT2 KMNIST\n",
      "num_commun: 400, loss: 23.8735839844, time pass: 78s | Local_SGD MT2 KMNIST\n",
      "num_commun: 500, loss: 23.6475029945, time pass: 99s | Local_SGD MT2 KMNIST\n",
      "num_commun: 600, loss: 23.4421475410, time pass: 117s | Local_SGD MT2 KMNIST\n",
      "num_commun: 700, loss: 23.2518233299, time pass: 136s | Local_SGD MT2 KMNIST\n",
      "num_commun: 800, loss: 23.0756085396, time pass: 156s | Local_SGD MT2 KMNIST\n",
      "num_commun: 900, loss: 22.9115986824, time pass: 176s | Local_SGD MT2 KMNIST\n",
      "num_commun: 1000, loss: 22.7549041748, time pass: 196s | Local_SGD MT2 KMNIST\n"
     ]
    }
   ],
   "source": [
    "loss_MT2_KMNIST_LocalSGD, _, _ = MT2.train_local_sgd(w_list0, beta_list0, sync_step, n_communs, devices_train_list, \n",
    "                                                     train_loader_list, lambda_global, lambda_penal, \n",
    "                                                     repo_step, eta, obj, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_commun: 1, loss: 25.2800841331, time pass: 0s | CD MT2 KMNIST\n",
      "num_commun: 100, loss: 23.4945446968, time pass: 6s | CD MT2 KMNIST\n",
      "num_commun: 200, loss: 22.4575186729, time pass: 13s | CD MT2 KMNIST\n",
      "num_commun: 300, loss: 21.6199242592, time pass: 19s | CD MT2 KMNIST\n",
      "num_commun: 400, loss: 20.8776302338, time pass: 25s | CD MT2 KMNIST\n",
      "num_commun: 500, loss: 20.1979004860, time pass: 32s | CD MT2 KMNIST\n",
      "num_commun: 600, loss: 19.6467130661, time pass: 38s | CD MT2 KMNIST\n",
      "num_commun: 700, loss: 19.0215931892, time pass: 45s | CD MT2 KMNIST\n",
      "num_commun: 800, loss: 18.5061625957, time pass: 51s | CD MT2 KMNIST\n",
      "num_commun: 900, loss: 17.9969273567, time pass: 58s | CD MT2 KMNIST\n",
      "num_commun: 1000, loss: 17.5365687370, time pass: 66s | CD MT2 KMNIST\n"
     ]
    }
   ],
   "source": [
    "loss_MT2_KMNIST_CD, _, _ = MT2.train_CD(w0, beta0, n_communs, devices_train_list, \n",
    "                                       train_loader_list, lambda_global, lambda_penal, \n",
    "                                       repo_step, eta, prob1, obj, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_commun: 1, loss: 25.2862764359, time pass: 0s | CDVR MT2 KMNIST\n",
      "num_commun: 100, loss: 23.3064260483, time pass: 10s | CDVR MT2 KMNIST\n",
      "num_commun: 200, loss: 22.5364636421, time pass: 19s | CDVR MT2 KMNIST\n",
      "num_commun: 300, loss: 21.5625555992, time pass: 29s | CDVR MT2 KMNIST\n",
      "num_commun: 400, loss: 20.8356351852, time pass: 38s | CDVR MT2 KMNIST\n",
      "num_commun: 500, loss: 20.2600438118, time pass: 48s | CDVR MT2 KMNIST\n",
      "num_commun: 600, loss: 19.7138942242, time pass: 57s | CDVR MT2 KMNIST\n",
      "num_commun: 700, loss: 19.0494834423, time pass: 67s | CDVR MT2 KMNIST\n",
      "num_commun: 800, loss: 18.5315414906, time pass: 76s | CDVR MT2 KMNIST\n",
      "num_commun: 900, loss: 18.0122313023, time pass: 86s | CDVR MT2 KMNIST\n",
      "num_commun: 1000, loss: 17.5447692871, time pass: 95s | CDVR MT2 KMNIST\n"
     ]
    }
   ],
   "source": [
    "loss_MT2_KMNIST_CDVR, _, _ = MT2.train_CDVR(w0, beta0, n_communs, devices_train_list, \n",
    "                                           train_loader_list, lambda_global, lambda_penal, \n",
    "                                           repo_step, eta, prob1, rho, obj, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./result/loss_MT2_KMNIST_CD.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(loss_MT2_KMNIST_CD, f)\n",
    "    \n",
    "with open(\"./result/loss_MT2_KMNIST_CDVR.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(loss_MT2_KMNIST_CDVR, f)\n",
    "    \n",
    "with open(\"./result/loss_MT2_KMNIST_LocalSGD.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(loss_MT2_KMNIST_LocalSGD, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
