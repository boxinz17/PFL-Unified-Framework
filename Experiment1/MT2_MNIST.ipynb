{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2230793ff50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load packages and set up default settings\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "import data_load\n",
    "import MT2\n",
    "\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all parameters\n",
    "lambda_global = 10\n",
    "lambda_penal = 1\n",
    "\n",
    "M = 10\n",
    "n_samples = 100\n",
    "\n",
    "obj = 'MT2'\n",
    "data_name = 'MNIST'\n",
    "\n",
    "L_w = (lambda_global + lambda_penal) / M\n",
    "L_beta = 1 + lambda_penal\n",
    "\n",
    "prob1 = L_w / (L_w + L_beta)\n",
    "prob2 = 1 - prob1\n",
    "\n",
    "eta = 1e-1\n",
    "\n",
    "rho = 1e-2\n",
    "\n",
    "n_communs = 1000\n",
    "repo_step = 100\n",
    "sync_step = 5\n",
    "\n",
    "w0 = [torch.zeros(10, 784).to(device), torch.zeros(10).to(device)]\n",
    "\n",
    "beta0 = []\n",
    "for m in range(M):\n",
    "    beta0.append([torch.zeros(10, 784).to(device), torch.zeros(10).to(device)])\n",
    "    \n",
    "w_list0 = []\n",
    "for m in range(M):\n",
    "    w_list0.append([torch.zeros(10, 784).to(device), torch.zeros(10).to(device)])\n",
    "\n",
    "beta_list0 = []\n",
    "for m in range(M):\n",
    "    beta_list0.append([torch.zeros(10, 784).to(device), torch.zeros(10).to(device)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L_w is: 1.1\n",
      "L_beta is 0.2\n",
      "prob1 is 0.8461538461538461\n",
      "prob2 is 0.15384615384615385\n",
      "eta is 0.1\n",
      "rho is 0.01\n",
      "n_communs is 1000\n",
      "sync_step is 5\n"
     ]
    }
   ],
   "source": [
    "print(\"L_w is: {}\".format(L_w))\n",
    "print(\"L_beta is {}\".format(L_beta))\n",
    "print(\"prob1 is {}\".format(prob1))\n",
    "print(\"prob2 is {}\".format(prob2))\n",
    "print(\"eta is {}\".format(eta))\n",
    "print(\"rho is {}\".format(rho))\n",
    "print(\"n_communs is {}\".format(n_communs))\n",
    "print(\"sync_step is {}\".format(sync_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_list, devices_train_list = data_load.data_prepare(data_name, n_devices=M, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_commun: 1, loss: 25.3284320831, time pass: 0s | Local_SGD MT2 MNIST\n",
      "num_commun: 100, loss: 24.6433942795, time pass: 17s | Local_SGD MT2 MNIST\n",
      "num_commun: 200, loss: 24.2255694389, time pass: 34s | Local_SGD MT2 MNIST\n",
      "num_commun: 300, loss: 23.8831072807, time pass: 49s | Local_SGD MT2 MNIST\n",
      "num_commun: 400, loss: 23.5901333809, time pass: 65s | Local_SGD MT2 MNIST\n",
      "num_commun: 500, loss: 23.3140561104, time pass: 82s | Local_SGD MT2 MNIST\n",
      "num_commun: 600, loss: 23.0625981331, time pass: 98s | Local_SGD MT2 MNIST\n",
      "num_commun: 700, loss: 22.8331655502, time pass: 113s | Local_SGD MT2 MNIST\n",
      "num_commun: 800, loss: 22.6161151886, time pass: 130s | Local_SGD MT2 MNIST\n",
      "num_commun: 900, loss: 22.4090280533, time pass: 145s | Local_SGD MT2 MNIST\n",
      "num_commun: 1000, loss: 22.2120543480, time pass: 160s | Local_SGD MT2 MNIST\n"
     ]
    }
   ],
   "source": [
    "loss_MT2_MNIST_LocalSGD, _, _ = MT2.train_local_sgd(w_list0, beta_list0, sync_step, n_communs, devices_train_list, \n",
    "                                                     train_loader_list, lambda_global, lambda_penal, \n",
    "                                                     repo_step, eta, obj, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_commun: 1, loss: 25.2781715393, time pass: 0s | CD MT2 MNIST\n",
      "num_commun: 100, loss: 23.1097467422, time pass: 4s | CD MT2 MNIST\n",
      "num_commun: 200, loss: 21.8042819023, time pass: 9s | CD MT2 MNIST\n",
      "num_commun: 300, loss: 20.7007495880, time pass: 14s | CD MT2 MNIST\n",
      "num_commun: 400, loss: 19.7506006718, time pass: 19s | CD MT2 MNIST\n",
      "num_commun: 500, loss: 18.7554688931, time pass: 24s | CD MT2 MNIST\n",
      "num_commun: 600, loss: 17.9864258766, time pass: 29s | CD MT2 MNIST\n",
      "num_commun: 700, loss: 17.1496109009, time pass: 34s | CD MT2 MNIST\n",
      "num_commun: 800, loss: 16.4925632477, time pass: 39s | CD MT2 MNIST\n",
      "num_commun: 900, loss: 15.7995675087, time pass: 44s | CD MT2 MNIST\n",
      "num_commun: 1000, loss: 15.2127392769, time pass: 49s | CD MT2 MNIST\n"
     ]
    }
   ],
   "source": [
    "loss_MT2_MNIST_CD, _, _ = MT2.train_CD(w0, beta0, n_communs, devices_train_list, \n",
    "                                       train_loader_list, lambda_global, lambda_penal, \n",
    "                                       repo_step, eta, prob1, obj, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_commun: 1, loss: 25.2772511482, time pass: 0s | CDVR MT2 MNIST\n",
      "num_commun: 100, loss: 22.8898561478, time pass: 7s | CDVR MT2 MNIST\n",
      "num_commun: 200, loss: 21.9230146408, time pass: 14s | CDVR MT2 MNIST\n",
      "num_commun: 300, loss: 20.6447943687, time pass: 21s | CDVR MT2 MNIST\n",
      "num_commun: 400, loss: 19.6485673904, time pass: 29s | CDVR MT2 MNIST\n",
      "num_commun: 500, loss: 18.8457640648, time pass: 36s | CDVR MT2 MNIST\n",
      "num_commun: 600, loss: 18.0835960865, time pass: 43s | CDVR MT2 MNIST\n",
      "num_commun: 700, loss: 17.1905948162, time pass: 50s | CDVR MT2 MNIST\n",
      "num_commun: 800, loss: 16.4883113861, time pass: 58s | CDVR MT2 MNIST\n",
      "num_commun: 900, loss: 15.7983124733, time pass: 65s | CDVR MT2 MNIST\n",
      "num_commun: 1000, loss: 15.1837946415, time pass: 73s | CDVR MT2 MNIST\n"
     ]
    }
   ],
   "source": [
    "loss_MT2_MNIST_CDVR, _, _ = MT2.train_CDVR(w0, beta0, n_communs, devices_train_list, \n",
    "                                           train_loader_list, lambda_global, lambda_penal, \n",
    "                                           repo_step, eta, prob1, rho, obj, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./result/loss_MT2_MNIST_CD.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(loss_MT2_MNIST_CD, f)\n",
    "    \n",
    "with open(\"./result/loss_MT2_MNIST_CDVR.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(loss_MT2_MNIST_CDVR, f)\n",
    "    \n",
    "with open(\"./result/loss_MT2_MNIST_LocalSGD.txt\", \"wb\") as f:   #Pickling\n",
    "    pickle.dump(loss_MT2_MNIST_LocalSGD, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
